```python
"""水果识别(分类)示例
 数据集：利用爬虫从互联网爬取的1036张水果图片
        共5个类别（苹果288张、香蕉275张、葡萄216张、橙子276张、梨251张）
任务：利用本数据集训练模型，用于水果识别
"""
import os

# 定义一组变量
name_dict = {"apple": 0, "banana": 1, "grape": 2, "orange": 3, "pear": 4}  # 水果名称和数组对应字典
data_root_path = "fruits/"  # 数据样本所在目录
test_file_path = data_root_path + "test.txt"  # 测试集文件路径
train_file_path = data_root_path + "train.txt"  # 训练集文件路径
name_data_list = {}  # 记录每个类别的图片路径


# 将文件路径存入临时字典
def save_train_test_file(path, name):
    if name not in name_data_list:  # 当前水果没有在字典中，新增
        img_list = []
        img_list.append(path)  # 将图片添加到列表
        name_data_list[name] = img_list  # 将“名称-图片列表”键值对插入字典
    else:  # 当前水果已经在字典中，添加到相应的列表
        name_data_list[name].append(path)


# 遍历所有子目录，读取出所有图片文件，并插入字典、保存到测试集、训练集
dirs = os.listdir(data_root_path)
for d in dirs:
    full_path = data_root_path + d  # 目录名称 + 子目录名称

    if os.path.isdir(full_path):  # 目录
        imgs = os.listdir(full_path)  # 列出子目录中的文件
        for img in imgs:
            save_train_test_file(full_path + "/" + img,  # 图片文件完整路径
                                 d)  # 子目录名称（类别名称）
    else:  # 文件
        pass

# 将字典中的内容保存文件中
with open(test_file_path, "w") as f:  # 清空测试集文件
    pass
with open(train_file_path, "w") as f:  # 清空训练集文件
    pass

# 遍历字典，将内容写入文件
for name, img_list in name_data_list.items():
    i = 0
    num = len(img_list)  # 每个类别图片数量
    print("%s: %d张图像" % (name, num))

    for img in img_list:  # 遍历每个列表，将图片路径存入文件
        if i % 10 == 0:  # 每10张写一张到测试集
            with open(test_file_path, "a") as f:
                line = "%s\t%d\n" % (img, name_dict[name])
                f.write(line)  # 写入文件
        else:  # 其它写入训练集
            with open(train_file_path, "a") as f:
                line = "%s\t%d\n" % (img, name_dict[name])
                f.write(line)  # 写入文件
        i += 1

print("数据预处理完成.")
```

    apple: 288张图像
    pear: 251张图像
    banana: 275张图像
    orange: 276张图像
    grape: 216张图像
    数据预处理完成.



```python
"""模型搭建、训练"""
import paddle
import paddle.fluid as fluid
import numpy as np
import sys
import os
from multiprocessing import cpu_count
import matplotlib.pyplot as plt


# 数据准备
## 定义reader
## train_mapper函数：对传入的图片路径进行读取，返回图像数据（多通道矩阵）、标签
def train_mapper(sample):
    img, label = sample  # 将sample中值赋给img, label

    if not os.path.exists(img):
        print(img, "图片文件不存在")

    # 读取图片文件
    img = paddle.dataset.image.load_image(img)  # 读取图片
    # 对图像进行简单变换：修剪、设置大小，输出(3, 100, 100)张量
    img = paddle.dataset.image.simple_transform(im=img,  # 原图像数据
                                                resize_size=100,  # 重设图像大小为100*100
                                                crop_size=100,  # 裁剪成100*100
                                                is_color=True,  # 彩色图像
                                                is_train=True)  # 是否用于训练，影响裁剪策略
    # 对图像数据进行归一化处理，像素的值全部计算压缩到0~1之间
    img = img.astype("float32") / 255.0

    return img, label  # 返回图像数据、标签


# 读取训练集文件，将路径、标签作为参数调用train_mapper函数
def train_r(train_list, buffered_size=1024):
    def reader():
        with open(train_list, "r") as f:  # 打开训练集
            lines = [line.strip() for line in f]  # 读取出所有样本行

            for line in lines:
                # 去掉每行的换行符，并根据tab字符进行拆分，得到两个字段
                img_path, lab = line.replace("\n", "").split("\t")
                yield img_path, int(lab)

    # xmap_readers高阶函数，作用是将reader产生的数据穿个train_mapper函数进行下一步处理
    return paddle.reader.xmap_readers(train_mapper,  # 二次处理函数
                                      reader,  # 原始reader
                                      cpu_count(),  # 线程数(和cpu数量一致)
                                      buffered_size)  # 缓冲区大小


BATCH_SIZE = 32  # 批次大小

# 定义reader
train_reader = train_r(train_list=train_file_path)  # train_file_path为训练集文件路径
random_train_reader = paddle.reader.shuffle(reader=train_reader,  # 原始reader
                                            buf_size=1300)  # 缓冲区大小
batch_train_reader = paddle.batch(random_train_reader,
                                  batch_size=BATCH_SIZE)  # 批量读取器
# 定义变量
image = fluid.layers.data(name="image", shape=[3, 100, 100], dtype="float32")
label = fluid.layers.data(name="label", shape=[1], dtype="int64")


# 创建VGG模型
def vgg_bn_drop(image, type_size):
    def conv_block(ipt, num_filter, groups, dropouts):
        # 创建Convolution2d, BatchNorm, DropOut, Pool2d组
        return fluid.nets.img_conv_group(input=ipt,  # 输入图像像，[N,C,H,W]格式
                                         pool_stride=2,  # 池化步长值
                                         pool_size=2,  # 池化区域大小
                                         conv_num_filter=[num_filter] * groups,  # 卷积核数量
                                         conv_filter_size=3,  # 卷积核大小
                                         conv_act="relu",  # 激活函数
                                         conv_with_batchnorm=True,  # 是否使用batch normal
                                         pool_type="max")  # 池化类型

    conv1 = conv_block(image, 64, 2, [0.0, 0])  # 最后一个参数个数和组数量相对应
    conv2 = conv_block(conv1, 128, 2, [0.0, 0])
    conv3 = conv_block(conv2, 256, 3, [0.0, 0.0, 0.0])
    conv4 = conv_block(conv3, 512, 3, [0.0, 0.0, 0.0])
    conv5 = conv_block(conv4, 512, 3, [0.0, 0.0, 0.0])

    drop = fluid.layers.dropout(x=conv5, dropout_prob=0.5)  # 待调整
    fc1 = fluid.layers.fc(input=drop, size=512, act=None)

    bn = fluid.layers.batch_norm(input=fc1, act="relu")  # batch normal
    drop2 = fluid.layers.dropout(x=bn, dropout_prob=0.0)
    fc2 = fluid.layers.fc(input=drop2, size=512, act=None)
    predict = fluid.layers.fc(input=fc2, size=type_size, act="softmax")

    return predict


# 调用上面的函数创建VGG
predict = vgg_bn_drop(image=image, type_size=5)  # type_size和水果类别一致
# 损失函数
cost = fluid.layers.cross_entropy(input=predict,  # 预测值
                                  label=label)  # 真实值
avg_cost = fluid.layers.mean(cost)
# 计算准确率
accuracy = fluid.layers.accuracy(input=predict,  # 预测值
                                 label=label)  # 真实值
# 优化器
optimizer = fluid.optimizer.Adam(learning_rate=0.001)  # 自适应梯度下降优化器
optimizer.minimize(avg_cost)

# 创建Executor
place = fluid.CUDAPlace(0)  # GPU上执行
exe = fluid.Executor(place)  # 执行器
exe.run(fluid.default_startup_program())  # 初始化

# 定义feeder
feeder = fluid.DataFeeder(feed_list=[image, label], place=place)

costs = []  # 记录损失值
accs = []  # 记录准确率
times = 0
batches = []  # 记录批次

for pass_id in range(80):
    train_cost = 0

    for batch_id, data in enumerate(batch_train_reader()):
        times += 1

        train_cost, train_acc = exe.run(program=fluid.default_main_program(),
                                        feed=feeder.feed(data),  # 喂入一个batch数据
                                        fetch_list=[avg_cost, accuracy])  # 获取结果
        if batch_id % 20 == 0:
            print("pass_id:%d, bat_id:%d, cost:%f, acc:%f" %
                  (pass_id, batch_id, train_cost[0], train_acc[0]))
            accs.append(train_acc[0])  # 记录准确率
            costs.append(train_cost[0])  # 记录损失值
            batches.append(times)  # 记录训练批次数

# 保存模型
model_save_dir = "model/fruits/"  # 模型保存路径
if not os.path.exists(model_save_dir):  # 如果模型路径不存在则创建
    os.makedirs(model_save_dir)
fluid.io.save_inference_model(dirname=model_save_dir,  # 保存路径
                              feeded_var_names=["image"],  # 使用模型需传入的参数
                              target_vars=[predict],  # 模型结果
                              executor=exe)  # 模型
print("模型保存完成.")

# 训练过程可视化
plt.title("training", fontsize=24)
plt.xlabel("iter", fontsize=20)
plt.ylabel("cost/acc", fontsize=20)
plt.plot(batches, costs, color='red', label="Training Cost")
plt.plot(batches, accs, color='green', label="Training Acc")
plt.legend()
plt.grid()
plt.show()
plt.savefig("train.png")
```

    pass_id:0, bat_id:0, cost:2.017712, acc:0.125000
    pass_id:0, bat_id:20, cost:0.576268, acc:0.750000
    pass_id:1, bat_id:0, cost:1.065507, acc:0.656250
    pass_id:1, bat_id:20, cost:1.067040, acc:0.750000
    pass_id:2, bat_id:0, cost:0.831544, acc:0.718750
    pass_id:2, bat_id:20, cost:0.501433, acc:0.843750
    pass_id:3, bat_id:0, cost:0.556549, acc:0.812500
    pass_id:3, bat_id:20, cost:0.557789, acc:0.843750
    pass_id:4, bat_id:0, cost:0.791796, acc:0.812500
    pass_id:4, bat_id:20, cost:0.550777, acc:0.812500
    pass_id:5, bat_id:0, cost:0.610251, acc:0.843750
    pass_id:5, bat_id:20, cost:0.321239, acc:0.937500
    pass_id:6, bat_id:0, cost:0.501548, acc:0.781250
    pass_id:6, bat_id:20, cost:1.553298, acc:0.593750
    pass_id:7, bat_id:0, cost:1.010339, acc:0.718750
    pass_id:7, bat_id:20, cost:0.679760, acc:0.718750
    pass_id:8, bat_id:0, cost:0.927081, acc:0.593750
    pass_id:8, bat_id:20, cost:1.231585, acc:0.593750
    pass_id:9, bat_id:0, cost:1.032748, acc:0.718750
    pass_id:9, bat_id:20, cost:1.174342, acc:0.718750
    pass_id:10, bat_id:0, cost:1.313228, acc:0.625000
    pass_id:10, bat_id:20, cost:0.682291, acc:0.750000
    pass_id:11, bat_id:0, cost:0.983149, acc:0.625000
    pass_id:11, bat_id:20, cost:0.653159, acc:0.781250
    pass_id:12, bat_id:0, cost:0.843967, acc:0.750000
    pass_id:12, bat_id:20, cost:1.154780, acc:0.750000
    pass_id:13, bat_id:0, cost:0.590434, acc:0.718750
    pass_id:13, bat_id:20, cost:0.909620, acc:0.625000
    pass_id:14, bat_id:0, cost:0.563538, acc:0.812500
    pass_id:14, bat_id:20, cost:0.416359, acc:0.843750
    pass_id:15, bat_id:0, cost:0.718626, acc:0.718750
    pass_id:15, bat_id:20, cost:0.606807, acc:0.750000
    pass_id:16, bat_id:0, cost:0.790871, acc:0.593750
    pass_id:16, bat_id:20, cost:1.535139, acc:0.562500
    pass_id:17, bat_id:0, cost:1.378309, acc:0.343750
    pass_id:17, bat_id:20, cost:1.135127, acc:0.468750
    pass_id:18, bat_id:0, cost:0.885330, acc:0.687500
    pass_id:18, bat_id:20, cost:1.066382, acc:0.625000
    pass_id:19, bat_id:0, cost:0.989122, acc:0.500000
    pass_id:19, bat_id:20, cost:1.097829, acc:0.468750
    pass_id:20, bat_id:0, cost:1.165941, acc:0.531250
    pass_id:20, bat_id:20, cost:0.855400, acc:0.656250
    pass_id:21, bat_id:0, cost:1.307731, acc:0.437500
    pass_id:21, bat_id:20, cost:1.089420, acc:0.656250
    pass_id:22, bat_id:0, cost:1.048174, acc:0.468750
    pass_id:22, bat_id:20, cost:1.093638, acc:0.500000
    pass_id:23, bat_id:0, cost:0.978342, acc:0.625000
    pass_id:23, bat_id:20, cost:1.319953, acc:0.531250
    pass_id:24, bat_id:0, cost:1.267755, acc:0.406250
    pass_id:24, bat_id:20, cost:1.121784, acc:0.437500
    pass_id:25, bat_id:0, cost:1.083033, acc:0.468750
    pass_id:25, bat_id:20, cost:1.028070, acc:0.562500
    pass_id:26, bat_id:0, cost:1.087278, acc:0.500000
    pass_id:26, bat_id:20, cost:0.992610, acc:0.531250
    pass_id:27, bat_id:0, cost:1.229454, acc:0.500000
    pass_id:27, bat_id:20, cost:1.160724, acc:0.437500
    pass_id:28, bat_id:0, cost:1.069041, acc:0.562500
    pass_id:28, bat_id:20, cost:1.371607, acc:0.406250
    pass_id:29, bat_id:0, cost:1.281320, acc:0.437500
    pass_id:29, bat_id:20, cost:1.069557, acc:0.625000
    pass_id:30, bat_id:0, cost:1.069296, acc:0.562500
    pass_id:30, bat_id:20, cost:0.959492, acc:0.625000
    pass_id:31, bat_id:0, cost:1.325713, acc:0.437500
    pass_id:31, bat_id:20, cost:0.949149, acc:0.656250
    pass_id:32, bat_id:0, cost:0.921006, acc:0.593750
    pass_id:32, bat_id:20, cost:1.297058, acc:0.437500
    pass_id:33, bat_id:0, cost:1.334042, acc:0.437500
    pass_id:33, bat_id:20, cost:1.269806, acc:0.406250
    pass_id:34, bat_id:0, cost:1.030157, acc:0.531250
    pass_id:34, bat_id:20, cost:1.197769, acc:0.500000
    pass_id:35, bat_id:0, cost:0.802201, acc:0.593750
    pass_id:35, bat_id:20, cost:1.341497, acc:0.468750
    pass_id:36, bat_id:0, cost:1.065158, acc:0.437500
    pass_id:36, bat_id:20, cost:1.524288, acc:0.531250
    pass_id:37, bat_id:0, cost:1.111157, acc:0.468750
    pass_id:37, bat_id:20, cost:1.069618, acc:0.562500
    pass_id:38, bat_id:0, cost:0.889926, acc:0.687500
    pass_id:38, bat_id:20, cost:0.967939, acc:0.500000
    pass_id:39, bat_id:0, cost:1.199193, acc:0.468750
    pass_id:39, bat_id:20, cost:0.947809, acc:0.562500
    pass_id:40, bat_id:0, cost:1.259386, acc:0.343750
    pass_id:40, bat_id:20, cost:0.937859, acc:0.593750
    pass_id:41, bat_id:0, cost:1.088146, acc:0.562500
    pass_id:41, bat_id:20, cost:0.891762, acc:0.593750
    pass_id:42, bat_id:0, cost:1.400941, acc:0.437500
    pass_id:42, bat_id:20, cost:0.990195, acc:0.531250
    pass_id:43, bat_id:0, cost:1.053352, acc:0.562500
    pass_id:43, bat_id:20, cost:0.908107, acc:0.562500
    pass_id:44, bat_id:0, cost:1.103482, acc:0.593750
    pass_id:44, bat_id:20, cost:0.838824, acc:0.718750
    pass_id:45, bat_id:0, cost:1.063680, acc:0.656250
    pass_id:45, bat_id:20, cost:1.265298, acc:0.468750
    pass_id:46, bat_id:0, cost:0.780575, acc:0.687500
    pass_id:46, bat_id:20, cost:0.897693, acc:0.656250
    pass_id:47, bat_id:0, cost:1.056720, acc:0.562500
    pass_id:47, bat_id:20, cost:1.294376, acc:0.437500
    pass_id:48, bat_id:0, cost:0.984946, acc:0.593750
    pass_id:48, bat_id:20, cost:1.554499, acc:0.375000
    pass_id:49, bat_id:0, cost:0.836982, acc:0.687500
    pass_id:49, bat_id:20, cost:1.099628, acc:0.531250
    pass_id:50, bat_id:0, cost:0.801800, acc:0.625000
    pass_id:50, bat_id:20, cost:0.927236, acc:0.593750
    pass_id:51, bat_id:0, cost:1.454378, acc:0.375000
    pass_id:51, bat_id:20, cost:1.179218, acc:0.500000
    pass_id:52, bat_id:0, cost:1.153623, acc:0.531250
    pass_id:52, bat_id:20, cost:1.054258, acc:0.531250
    pass_id:53, bat_id:0, cost:1.144059, acc:0.500000
    pass_id:53, bat_id:20, cost:1.281265, acc:0.375000
    pass_id:54, bat_id:0, cost:0.850076, acc:0.656250
    pass_id:54, bat_id:20, cost:1.043788, acc:0.437500
    pass_id:55, bat_id:0, cost:1.238417, acc:0.500000
    pass_id:55, bat_id:20, cost:1.105791, acc:0.625000
    pass_id:56, bat_id:0, cost:0.999826, acc:0.593750
    pass_id:56, bat_id:20, cost:0.983663, acc:0.406250
    pass_id:57, bat_id:0, cost:0.927114, acc:0.531250
    pass_id:57, bat_id:20, cost:0.730324, acc:0.750000
    pass_id:58, bat_id:0, cost:1.050425, acc:0.406250
    pass_id:58, bat_id:20, cost:1.327921, acc:0.531250
    pass_id:59, bat_id:0, cost:0.835528, acc:0.750000
    pass_id:59, bat_id:20, cost:1.178178, acc:0.500000
    pass_id:60, bat_id:0, cost:1.017931, acc:0.593750
    pass_id:60, bat_id:20, cost:0.927242, acc:0.562500
    pass_id:61, bat_id:0, cost:1.100168, acc:0.531250
    pass_id:61, bat_id:20, cost:0.961644, acc:0.687500
    pass_id:62, bat_id:0, cost:1.116126, acc:0.468750
    pass_id:62, bat_id:20, cost:1.043539, acc:0.562500
    pass_id:63, bat_id:0, cost:1.019505, acc:0.593750
    pass_id:63, bat_id:20, cost:1.162525, acc:0.562500
    pass_id:64, bat_id:0, cost:0.931574, acc:0.593750
    pass_id:64, bat_id:20, cost:1.012251, acc:0.562500
    pass_id:65, bat_id:0, cost:0.977677, acc:0.625000
    pass_id:65, bat_id:20, cost:1.174156, acc:0.562500
    pass_id:66, bat_id:0, cost:1.162004, acc:0.531250
    pass_id:66, bat_id:20, cost:1.343483, acc:0.437500
    pass_id:67, bat_id:0, cost:1.168733, acc:0.500000
    pass_id:67, bat_id:20, cost:0.919422, acc:0.687500
    pass_id:68, bat_id:0, cost:1.587478, acc:0.406250
    pass_id:68, bat_id:20, cost:1.138589, acc:0.562500
    pass_id:69, bat_id:0, cost:1.251781, acc:0.562500
    pass_id:69, bat_id:20, cost:1.141566, acc:0.437500
    pass_id:70, bat_id:0, cost:1.264854, acc:0.406250
    pass_id:70, bat_id:20, cost:1.176475, acc:0.500000
    pass_id:71, bat_id:0, cost:1.422444, acc:0.281250
    pass_id:71, bat_id:20, cost:1.086939, acc:0.500000
    pass_id:72, bat_id:0, cost:1.388586, acc:0.437500
    pass_id:72, bat_id:20, cost:1.550349, acc:0.343750
    pass_id:73, bat_id:0, cost:1.402426, acc:0.468750
    pass_id:73, bat_id:20, cost:1.352705, acc:0.406250
    pass_id:74, bat_id:0, cost:1.284149, acc:0.406250
    pass_id:74, bat_id:20, cost:1.385592, acc:0.406250
    pass_id:75, bat_id:0, cost:1.368434, acc:0.281250
    pass_id:75, bat_id:20, cost:1.300066, acc:0.437500
    pass_id:76, bat_id:0, cost:1.477603, acc:0.343750
    pass_id:76, bat_id:20, cost:1.220001, acc:0.531250
    pass_id:77, bat_id:0, cost:1.091466, acc:0.562500
    pass_id:77, bat_id:20, cost:1.159088, acc:0.562500
    pass_id:78, bat_id:0, cost:1.290032, acc:0.500000
    pass_id:78, bat_id:20, cost:1.268263, acc:0.437500
    pass_id:79, bat_id:0, cost:1.535745, acc:0.437500
    pass_id:79, bat_id:20, cost:1.294944, acc:0.531250
    模型保存完成.



    <Figure size 640x480 with 1 Axes>



```python
"""测试 """
from PIL import Image

# 创建执行器
place = fluid.CPUPlace()  # 测试时在CPU上执行
infer_exe = fluid.Executor(place)  # 执行器
model_save_dir = "model/fruits/"  # 模型所在路径


# 加载图片数据
def load_image(path):
    img = paddle.dataset.image.load_and_transform(path, 100, 100, False).astype("float32")
    img = img / 255.0  # 归一化处理
    return img  # 返回图像数据


infer_imgs = []  # 存放要预测图像
test_img = "train.png"  # 待预测图像

infer_imgs.append(load_image(test_img))
infer_imgs = np.array(infer_imgs)  # CNN要求传入张量，可以传入array

# 加载模型
infer_program, feed_target_names, fetch_targets = \
    fluid.io.load_inference_model(model_save_dir, infer_exe)

# 预测
results = infer_exe.run(program=infer_program,  # 执行预测program
                        feed={feed_target_names[0]: infer_imgs},  # 预测所需的参数
                        fetch_list=fetch_targets)  # 获取结果
print(results)

result = np.argmax(results[0])  # 获取预测结果中概率最大的值的索引
for k, v in name_dict.items():
    if result == v:  # 索引等于v
        print("预测结果:", k)  # 打印名称(k)

# 显示待预测图片
img = Image.open(test_img)
plt.imshow(img)
plt.show()
```

    [array([[0.13859648, 0.27476224, 0.00825502, 0.2869081 , 0.2914781 ]],
          dtype=float32)]
    预测结果: pear



![png](output_2_1.png)


请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>
Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. 
